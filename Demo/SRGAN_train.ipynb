{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Sv1VakOaaQ",
        "outputId": "95bbb9f6-6471-45c5-bbf2-e4623eb507ea"
      },
      "source": [
        "!pip install torch==1.2.0\n",
        "!pip install torchvision==0.4.0\n",
        "#torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.2.0\n",
            "  Downloading torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9 MB 636 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.2.0 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.2.0\n",
            "Collecting torchvision==0.4.0\n",
            "  Downloading torchvision-0.4.0-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.19.5)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "Successfully installed torchvision-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOC1tAfYMg2"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import argparse\n",
        "import os\n",
        "from math import log10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGO85qDpYdZa"
      },
      "source": [
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYTw3lztYm1v"
      },
      "source": [
        "import pytorch_ssim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzmLo9v3aGoe"
      },
      "source": [
        "''' DATA LOADER'''\n",
        "\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "def train_hr_transform(crop_size):\n",
        "    return Compose([\n",
        "        RandomCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "def train_lr_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "        super().__init__()\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
        "        self.hr_transform = train_hr_transform(crop_size)\n",
        "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
        "        lr_image = self.lr_transform(hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "class ValDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(ValDatasetFromFolder, self).__init__()\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = Image.open(self.image_filenames[index])\n",
        "        w, h = hr_image.size\n",
        "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
        "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
        "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
        "        hr_image = CenterCrop(crop_size)(hr_image)\n",
        "        lr_image = lr_scale(hr_image)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "class TestDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(TestDatasetFromFolder, self).__init__()\n",
        "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
        "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
        "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.lr_filenames[index].split('/')[-1]\n",
        "        lr_image = Image.open(self.lr_filenames[index])\n",
        "        w, h = lr_image.size\n",
        "        hr_image = Image.open(self.hr_filenames[index])\n",
        "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_filenames)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPhAI-_AaPaK"
      },
      "source": [
        "''' Generator Loss'''\n",
        "\n",
        "#import torch\n",
        "#from torch import nn\n",
        "from torchvision.models.vgg import vgg16\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super().__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        vgg = vgg16(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network.to('cuda')\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0HJTaVZa1or"
      },
      "source": [
        "''' Models '''\n",
        "#import torch\n",
        "import math\n",
        "#from torch import nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,scale_factor):\n",
        "        upsample_block_num = int(math.log(scale_factor,2))\n",
        "\n",
        "        super().__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3,64, kernel_size=9, padding = 4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64,64, kernel_size=3, padding = 1),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        block8 = [UpsampleBLock(64,2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(64, 3, kernel_size=9,padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return torch.sigmoid(self.net(x).view(batch_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzsqSF0g_u7v"
      },
      "source": [
        "def train(batch,epochs,train_loader, val_loader,):\n",
        "    results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "    for epoch in range(1,epochs):\n",
        "        running_results = {'d_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "        train_bar = tqdm(train_loader)\n",
        "        netG.train()\n",
        "        netD.train()\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "        for data,target in train_bar:\n",
        "            g_update_first = True\n",
        "            real_img = Variable(target)\n",
        "            real_img = real_img.to(device, dtype=torch.float32)\n",
        "            #if torch.cuda.is_available():\n",
        "                #real_img = real_img.cuda()\n",
        "            z = Variable(data)\n",
        "            z = z.to(device, dtype=torch.float32)\n",
        "            #if torch.cuda.is_available():\n",
        "                #z = z.cuda()\n",
        "            fake_img = netG(z)\n",
        "            netD.zero_grad()\n",
        "            real_out = netD(real_img).mean()\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            d_loss = 1 - real_out + fake_out\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizerD.step()\n",
        "\n",
        "            netG.zero_grad()\n",
        "\n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "\n",
        "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "            g_loss.backward()\n",
        "            \n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            \n",
        "            \n",
        "            optimizerG.step()\n",
        "            batch_size = batch\n",
        "            running_results['g_loss'] += g_loss.item() * batch_size\n",
        "            running_results['d_loss'] += d_loss.item() * batch_size\n",
        "            running_results['d_score'] += real_out.item() * batch_size\n",
        "            running_results['g_score'] += fake_out.item() * batch_size\n",
        "    \n",
        "            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "                epoch, epochs, running_results['d_loss'] / batch,\n",
        "                running_results['g_loss'] / batch,\n",
        "                running_results['d_score'] / batch,\n",
        "                running_results['g_score'] / batch))\n",
        "    \n",
        "        netG.eval()\n",
        "        out_path = 'training_results/SRF_' + str(2) + '/'\n",
        "        if not os.path.exists(out_path):\n",
        "            os.makedirs(out_path)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader)\n",
        "            valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "            val_images = []\n",
        "            for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "                batch_size = val_lr.size(0)\n",
        "                valing_results['batch_sizes'] += batch_size\n",
        "                lr = val_lr\n",
        "                hr = val_hr\n",
        "                if torch.cuda.is_available():\n",
        "                    lr = lr.cuda()\n",
        "                    hr = hr.cuda()\n",
        "                sr = netG(lr)\n",
        "        \n",
        "                batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "                valing_results['mse'] += batch_mse * batch_size\n",
        "                batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
        "                valing_results['ssims'] += batch_ssim * batch_size\n",
        "                valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "                valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
        "                val_bar.set_description(\n",
        "                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                        valing_results['psnr'], valing_results['ssim']))\n",
        "        \n",
        "                val_images.extend(\n",
        "                    [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "                     display_transform()(sr.data.cpu().squeeze(0))])\n",
        "            val_images = torch.stack(val_images)\n",
        "            val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "            val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "            index = 1\n",
        "            for image in val_save_bar:\n",
        "                image = utils.make_grid(image, nrow=3, padding=5)\n",
        "                utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "                index += 1\n",
        "        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (4, epoch))\n",
        "        torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (4, epoch))\n",
        "        results['d_loss'].append(running_results['d_loss'] / batch)\n",
        "        results['g_loss'].append(running_results['g_loss'] / batch)\n",
        "        results['d_score'].append(running_results['d_score'] / batch)\n",
        "        results['g_score'].append(running_results['g_score'] / batch)\n",
        "        results['psnr'].append(valing_results['psnr'])\n",
        "        results['ssim'].append(valing_results['ssim'])\n",
        "    \n",
        "        if epoch % 10 == 0 and epoch != 0:\n",
        "            out_path = 'statistics/'\n",
        "            data_frame = pd.DataFrame(\n",
        "                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "                index=range(1, epoch + 1))\n",
        "            data_frame.to_csv(out_path + 'srf_' + str(2) + '_train_results.csv', index_label='Epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gJdITgHMeLs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZn1GEa_MzlA"
      },
      "source": [
        "'''Download images'''\n",
        "\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwY2cezzWEXS"
      },
      "source": [
        "!unzip /content/DIV2K_train_HR.zip\n",
        "!unzip /content/DIV2K_valid_HR.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnVh56AGPTyt",
        "outputId": "2c4a9273-939e-48cf-9da7-65626b3e4bc4"
      },
      "source": [
        "'''using Dataloader'''\n",
        "from torch.utils.data import DataLoader\n",
        "train_img = TrainDatasetFromFolder(\n",
        "    dataset_dir= '/content/DIV2K_train_HR',\n",
        "    crop_size=88,\n",
        "    upscale_factor=2,\n",
        ")\n",
        "print(train_img)\n",
        "val_img = ValDatasetFromFolder(\n",
        "    dataset_dir= '/content/DIV2K_valid_HR',\n",
        "    upscale_factor=2,\n",
        ")\n",
        "\n",
        "''' val_set = ValDatasetFromFolder('data/DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)'''\n",
        "train_loader = DataLoader(dataset=train_img,num_workers=4, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_img,num_workers=4, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.TrainDatasetFromFolder object at 0x7f1b8cc57750>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Eeb6ldVQu8L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sifLQx0bXRb",
        "outputId": "00810b97-b1dd-4f46-f129-9407704becf4"
      },
      "source": [
        "netG = Generator(2)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# generator parameters: 586379\n",
            "# discriminator parameters: 5215425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dfCa6SEhdAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71595be-a9e5-4c61-b324-37d317abe4fb"
      },
      "source": [
        "generator_criterion = GeneratorLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:32<00:00, 17.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rtMW08dR30S"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxE48yKhmMA"
      },
      "source": [
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81fnPakFSBlK",
        "outputId": "b2b8c44e-d587-42fd-cacc-9cd453185f32"
      },
      "source": [
        "train(batch=32,epochs = 50, train_loader = train_loader,val_loader = val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/50] Loss_D: 24.9454 Loss_G: 0.2062 D(x): 10.8354 D(G(z)): 10.5746: 100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n",
            "[converting LR images to SR images] PSNR: 22.6442 dB SSIM: 0.6851: 100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[2/50] Loss_D: 25.0826 Loss_G: 0.1799 D(x): 10.6106 D(G(z)): 10.4817: 100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n",
            "[converting LR images to SR images] PSNR: 23.3863 dB SSIM: 0.6975: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[3/50] Loss_D: 25.1010 Loss_G: 0.1777 D(x): 7.7174 D(G(z)): 7.7860: 100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n",
            "[converting LR images to SR images] PSNR: 23.5094 dB SSIM: 0.7046: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n",
            "[4/50] Loss_D: 25.1055 Loss_G: 0.1626 D(x): 7.6415 D(G(z)): 7.7387: 100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n",
            "[converting LR images to SR images] PSNR: 24.0837 dB SSIM: 0.7199: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:17<00:00,  1.12it/s]\n",
            "[5/50] Loss_D: 25.1468 Loss_G: 0.1658 D(x): 7.4597 D(G(z)): 7.5744: 100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n",
            "[converting LR images to SR images] PSNR: 24.4697 dB SSIM: 0.7327: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n",
            "[6/50] Loss_D: 25.1291 Loss_G: 0.1540 D(x): 6.7462 D(G(z)): 6.8533: 100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n",
            "[converting LR images to SR images] PSNR: 24.3734 dB SSIM: 0.7311: 100%|██████████| 100/100 [02:33<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n",
            "[7/50] Loss_D: 25.1464 Loss_G: 0.1532 D(x): 6.4993 D(G(z)): 6.6367: 100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n",
            "[converting LR images to SR images] PSNR: 24.4591 dB SSIM: 0.7513: 100%|██████████| 100/100 [02:33<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:17<00:00,  1.12it/s]\n",
            "[8/50] Loss_D: 25.0304 Loss_G: 0.1624 D(x): 6.6342 D(G(z)): 6.6852: 100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n",
            "[converting LR images to SR images] PSNR: 24.8423 dB SSIM: 0.7600: 100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:17<00:00,  1.12it/s]\n",
            "[9/50] Loss_D: 24.9674 Loss_G: 0.1471 D(x): 7.5078 D(G(z)): 7.4863: 100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n",
            "[converting LR images to SR images] PSNR: 24.8612 dB SSIM: 0.7716: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:17<00:00,  1.11it/s]\n",
            "[10/50] Loss_D: 25.1177 Loss_G: 0.1380 D(x): 8.8423 D(G(z)): 8.9876: 100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n",
            "[converting LR images to SR images] PSNR: 25.3710 dB SSIM: 0.7769: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[11/50] Loss_D: 25.0365 Loss_G: 0.1219 D(x): 8.3911 D(G(z)): 8.3584: 100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n",
            "[converting LR images to SR images] PSNR: 25.4367 dB SSIM: 0.7850: 100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[12/50] Loss_D: 24.9846 Loss_G: 0.1195 D(x): 7.0314 D(G(z)): 6.9742: 100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n",
            "[converting LR images to SR images] PSNR: 25.7999 dB SSIM: 0.7969: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[13/50] Loss_D: 25.0845 Loss_G: 0.1160 D(x): 6.4915 D(G(z)): 6.5681: 100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n",
            "[converting LR images to SR images] PSNR: 25.7698 dB SSIM: 0.8011: 100%|██████████| 100/100 [02:33<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n",
            "[14/50] Loss_D: 25.0044 Loss_G: 0.1111 D(x): 8.0681 D(G(z)): 8.2243: 100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n",
            "[converting LR images to SR images] PSNR: 26.0346 dB SSIM: 0.8045: 100%|██████████| 100/100 [02:33<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n",
            "[15/50] Loss_D: 24.9798 Loss_G: 0.1119 D(x): 12.1741 D(G(z)): 12.3376: 100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n",
            "[converting LR images to SR images] PSNR: 25.8272 dB SSIM: 0.8073: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[16/50] Loss_D: 24.9998 Loss_G: 0.1063 D(x): 10.1842 D(G(z)): 9.7901: 100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n",
            "[converting LR images to SR images] PSNR: 25.4762 dB SSIM: 0.8178: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[17/50] Loss_D: 24.9979 Loss_G: 0.1140 D(x): 5.7970 D(G(z)): 5.6945: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 26.2577 dB SSIM: 0.8162: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[18/50] Loss_D: 24.9830 Loss_G: 0.1046 D(x): 5.0877 D(G(z)): 5.0428: 100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n",
            "[converting LR images to SR images] PSNR: 26.1614 dB SSIM: 0.8226: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[19/50] Loss_D: 25.0643 Loss_G: 0.1015 D(x): 6.4741 D(G(z)): 6.5830: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 26.6448 dB SSIM: 0.8303: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[20/50] Loss_D: 24.9643 Loss_G: 0.0934 D(x): 9.5022 D(G(z)): 9.6171: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 26.7398 dB SSIM: 0.8318: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[21/50] Loss_D: 24.9740 Loss_G: 0.1024 D(x): 11.3288 D(G(z)): 11.2626: 100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n",
            "[converting LR images to SR images] PSNR: 26.7642 dB SSIM: 0.8381: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[22/50] Loss_D: 25.0257 Loss_G: 0.1115 D(x): 10.0633 D(G(z)): 10.0564: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n",
            "[converting LR images to SR images] PSNR: 26.2791 dB SSIM: 0.8330: 100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[23/50] Loss_D: 25.0719 Loss_G: 0.1040 D(x): 9.2767 D(G(z)): 9.2831: 100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n",
            "[converting LR images to SR images] PSNR: 26.3668 dB SSIM: 0.8364: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[24/50] Loss_D: 25.0073 Loss_G: 0.0928 D(x): 9.5651 D(G(z)): 9.6027: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 27.0914 dB SSIM: 0.8450: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[25/50] Loss_D: 25.0407 Loss_G: 0.0908 D(x): 10.4380 D(G(z)): 10.4819: 100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n",
            "[converting LR images to SR images] PSNR: 26.6857 dB SSIM: 0.8452: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[26/50] Loss_D: 25.0286 Loss_G: 0.0877 D(x): 10.8960 D(G(z)): 10.9125: 100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n",
            "[converting LR images to SR images] PSNR: 27.2348 dB SSIM: 0.8541: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[27/50] Loss_D: 25.0625 Loss_G: 0.0845 D(x): 10.3243 D(G(z)): 10.4005: 100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n",
            "[converting LR images to SR images] PSNR: 26.8553 dB SSIM: 0.8559: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[28/50] Loss_D: 25.0392 Loss_G: 0.0818 D(x): 11.1435 D(G(z)): 11.2371: 100%|██████████| 25/25 [01:11<00:00,  2.84s/it]\n",
            "[converting LR images to SR images] PSNR: 27.5496 dB SSIM: 0.8553: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[29/50] Loss_D: 24.9876 Loss_G: 0.0796 D(x): 12.7890 D(G(z)): 12.7591: 100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n",
            "[converting LR images to SR images] PSNR: 25.7382 dB SSIM: 0.8537: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[30/50] Loss_D: 25.0795 Loss_G: 0.0893 D(x): 11.8923 D(G(z)): 11.9497: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 27.0562 dB SSIM: 0.8555: 100%|██████████| 100/100 [02:36<00:00,  1.57s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[31/50] Loss_D: 24.9396 Loss_G: 0.0822 D(x): 11.5052 D(G(z)): 11.2961: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n",
            "[converting LR images to SR images] PSNR: 27.7198 dB SSIM: 0.8576: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n",
            "[32/50] Loss_D: 25.0857 Loss_G: 0.0833 D(x): 7.2319 D(G(z)): 7.2237: 100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n",
            "[converting LR images to SR images] PSNR: 27.3717 dB SSIM: 0.8630: 100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n",
            "[33/50] Loss_D: 24.9396 Loss_G: 0.0884 D(x): 7.6156 D(G(z)): 7.6934: 100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n",
            "[converting LR images to SR images] PSNR: 25.6737 dB SSIM: 0.8454: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n",
            "[34/50] Loss_D: 25.1446 Loss_G: 0.0890 D(x): 9.1643 D(G(z)): 9.3048: 100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n",
            "[converting LR images to SR images] PSNR: 26.7230 dB SSIM: 0.8585: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n",
            "[35/50] Loss_D: 25.0455 Loss_G: 0.0862 D(x): 9.3582 D(G(z)): 9.3848: 100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n",
            "[converting LR images to SR images] PSNR: 27.3441 dB SSIM: 0.8608: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n",
            "[36/50] Loss_D: 24.9889 Loss_G: 0.0861 D(x): 8.4622 D(G(z)): 8.3960: 100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n",
            "[converting LR images to SR images] PSNR: 27.5643 dB SSIM: 0.8634: 100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n",
            "[37/50] Loss_D: 25.1058 Loss_G: 0.0800 D(x): 7.8999 D(G(z)): 7.9887: 100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n",
            "[converting LR images to SR images] PSNR: 27.5601 dB SSIM: 0.8656: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.05it/s]\n",
            "[38/50] Loss_D: 24.9699 Loss_G: 0.0793 D(x): 8.8450 D(G(z)): 8.8251: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "[converting LR images to SR images] PSNR: 27.2384 dB SSIM: 0.8685: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[39/50] Loss_D: 25.0584 Loss_G: 0.0796 D(x): 8.8571 D(G(z)): 8.7320: 100%|██████████| 25/25 [01:11<00:00,  2.88s/it]\n",
            "[converting LR images to SR images] PSNR: 26.4541 dB SSIM: 0.8703: 100%|██████████| 100/100 [02:36<00:00,  1.57s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[40/50] Loss_D: 25.0292 Loss_G: 0.0794 D(x): 6.6733 D(G(z)): 6.6941: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n",
            "[converting LR images to SR images] PSNR: 27.8802 dB SSIM: 0.8743: 100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n",
            "[41/50] Loss_D: 25.0099 Loss_G: 0.0774 D(x): 8.0566 D(G(z)): 8.0813: 100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n",
            "[converting LR images to SR images] PSNR: 27.7692 dB SSIM: 0.8714: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[42/50] Loss_D: 25.0262 Loss_G: 0.0794 D(x): 8.5678 D(G(z)): 8.5616: 100%|██████████| 25/25 [01:12<00:00,  2.88s/it]\n",
            "[converting LR images to SR images] PSNR: 27.0096 dB SSIM: 0.8697: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n",
            "[43/50] Loss_D: 24.9414 Loss_G: 0.0809 D(x): 8.7910 D(G(z)): 8.7065: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n",
            "[converting LR images to SR images] PSNR: 27.9513 dB SSIM: 0.8747: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[44/50] Loss_D: 25.0269 Loss_G: 0.0724 D(x): 8.7047 D(G(z)): 8.7716: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n",
            "[converting LR images to SR images] PSNR: 28.2511 dB SSIM: 0.8773: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
            "[45/50] Loss_D: 24.9682 Loss_G: 0.0779 D(x): 9.1819 D(G(z)): 9.0233: 100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n",
            "[converting LR images to SR images] PSNR: 27.8245 dB SSIM: 0.8766: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n",
            "[46/50] Loss_D: 24.9855 Loss_G: 0.0783 D(x): 7.6304 D(G(z)): 7.6128: 100%|██████████| 25/25 [01:12<00:00,  2.88s/it]\n",
            "[converting LR images to SR images] PSNR: 27.8176 dB SSIM: 0.8805: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[47/50] Loss_D: 25.0806 Loss_G: 0.0741 D(x): 7.9336 D(G(z)): 7.9502: 100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n",
            "[converting LR images to SR images] PSNR: 28.1020 dB SSIM: 0.8777: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[48/50] Loss_D: 25.0495 Loss_G: 0.0725 D(x): 8.2606 D(G(z)): 8.2989: 100%|██████████| 25/25 [01:11<00:00,  2.84s/it]\n",
            "[converting LR images to SR images] PSNR: 28.2076 dB SSIM: 0.8799: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n",
            "[49/50] Loss_D: 24.9512 Loss_G: 0.0722 D(x): 7.7188 D(G(z)): 7.5618: 100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n",
            "[converting LR images to SR images] PSNR: 28.5196 dB SSIM: 0.8826: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
            "[saving training results]: 100%|██████████| 20/20 [00:18<00:00,  1.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSAdbBEaUtTO"
      },
      "source": [
        "def test(model,UPSCALE_FACTOR):\n",
        "    model=model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "    test_set = TestDatasetFromFolder('/content/DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\n",
        "    test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
        "    test_bar = tqdm(test_loader, desc='[testing benchmark datasets]')\n",
        "\n",
        "    out_path = 'benchmark_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    for image_name, lr_image, hr_restore_img, hr_image in test_bar:\n",
        "        image_name = image_name[0]\n",
        "        lr_image = Variable(lr_image, volatile=True)\n",
        "        hr_image = Variable(hr_image, volatile=True)\n",
        "        if torch.cuda.is_available():\n",
        "            lr_image = lr_image.cuda()\n",
        "            hr_image = hr_image.cuda()\n",
        "\n",
        "        sr_image = model(lr_image)\n",
        "        mse = ((hr_image - sr_image) ** 2).data.mean()\n",
        "        psnr = 10 * log10(1 / mse)\n",
        "        ssim = pytorch_ssim.ssim(sr_image, hr_image).data[0]\n",
        "\n",
        "        test_images = torch.stack(\n",
        "            [display_transform()(hr_restore_img.squeeze(0)), display_transform()(hr_image.data.cpu().squeeze(0)),\n",
        "            display_transform()(sr_image.data.cpu().squeeze(0))])\n",
        "        image = utils.make_grid(test_images, nrow=3, padding=5)\n",
        "        utils.save_image(image, out_path + image_name.split('.')[0] + '_psnr_%.4f_ssim_%.4f.' % (psnr, ssim) +\n",
        "                        image_name.split('.')[-1], padding=5)\n",
        "\n",
        "        # save psnr\\ssim\n",
        "        results[image_name.split('_')[0]]['psnr'].append(psnr)\n",
        "        results[image_name.split('_')[0]]['ssim'].append(ssim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n4rritaXJhm"
      },
      "source": [
        "model = Generator(2).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkYELVYDXd4r"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "model.load_state_dict(torch.load('/content/netG_epoch_2_49 .pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugrshZQpXvuU",
        "outputId": "d46c5eaa-2650-4ef9-eff0-c4e2e041aa12"
      },
      "source": [
        "image = Image.open('/content/input/pic11.jpg')\n",
        "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
        "image = image.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Cdh-YoZyK6"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ABowRjYow5"
      },
      "source": [
        "with torch.no_grad():\n",
        "    out = model(image)\n",
        "    out_img = ToPILImage()(out[0].data.cpu())\n",
        "    out_img.save('/content/result/pic11_' + str(2) + '.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "W6WeMs5SmQRv",
        "outputId": "fc22bc93-2197-4a06-9d37-8d18ee2d6877"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' what to do\\n trian for 2X\\n complete test becnshmark\\n update documentation and individual files\\n update github\\n '"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}